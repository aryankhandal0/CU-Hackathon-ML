{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>CheckoutType</th>\n",
       "      <th>CheckoutYear</th>\n",
       "      <th>CheckoutMonth</th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Tidal wave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tsunamis, Tsunamis Juvenile literature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>London holiday / Richard Peck.</td>\n",
       "      <td>Peck, Richard, 1934-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viking,</td>\n",
       "      <td>1998.</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Cinco de Mayo : celebrating Hispanic pride / C...</td>\n",
       "      <td>Gnojewski, Carol</td>\n",
       "      <td>Cinco de Mayo Mexican holiday History Juvenile...</td>\n",
       "      <td>Enslow Publishers,</td>\n",
       "      <td>c2002.</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>War stories, Historical fiction, Domestic fict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>As a man thinketh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thought and thinking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID UsageClass CheckoutType  CheckoutYear  CheckoutMonth  Checkouts  \\\n",
       "0   1   Physical      Horizon          2005              4          1   \n",
       "1   2   Physical      Horizon          2005              4          1   \n",
       "2   3   Physical      Horizon          2005              4          3   \n",
       "3   4   Physical      Horizon          2005              4          1   \n",
       "4   5   Physical      Horizon          2005              4          1   \n",
       "\n",
       "                                               Title               Creator  \\\n",
       "0                                         Tidal wave                   NaN   \n",
       "1                     London holiday / Richard Peck.  Peck, Richard, 1934-   \n",
       "2  Cinco de Mayo : celebrating Hispanic pride / C...      Gnojewski, Carol   \n",
       "3                                          Annapolis                   NaN   \n",
       "4                                  As a man thinketh                   NaN   \n",
       "\n",
       "                                            Subjects           Publisher  \\\n",
       "0             Tsunamis, Tsunamis Juvenile literature                 NaN   \n",
       "1                                                NaN             Viking,   \n",
       "2  Cinco de Mayo Mexican holiday History Juvenile...  Enslow Publishers,   \n",
       "3  War stories, Historical fiction, Domestic fict...                 NaN   \n",
       "4                               Thought and thinking                 NaN   \n",
       "\n",
       "  PublicationYear MaterialType  \n",
       "0             NaN         BOOK  \n",
       "1           1998.         BOOK  \n",
       "2          c2002.         BOOK  \n",
       "3             NaN         BOOK  \n",
       "4             NaN         BOOK  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31653 entries, 0 to 31652\n",
      "Data columns (total 12 columns):\n",
      "ID                 31653 non-null int64\n",
      "UsageClass         31653 non-null object\n",
      "CheckoutType       31653 non-null object\n",
      "CheckoutYear       31653 non-null int64\n",
      "CheckoutMonth      31653 non-null int64\n",
      "Checkouts          31653 non-null int64\n",
      "Title              31653 non-null object\n",
      "Creator            8516 non-null object\n",
      "Subjects           29890 non-null object\n",
      "Publisher          9737 non-null object\n",
      "PublicationYear    9722 non-null object\n",
      "MaterialType       31653 non-null object\n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID','CheckoutType','CheckoutYear','CheckoutMonth','Creator','Subjects','Publisher','PublicationYear','CheckoutType'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    '''\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "bow_transformer = TfidfVectorizer(analyzer=text_process).fit(x)\n",
    "X = bow_transformer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['MaterialType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31653x39279 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 165155 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 0, 2])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpred(nb):\n",
    "    nb.fit(X_train, y_train)\n",
    "    preds = nb.predict(X_test)\n",
    "    mat = confusion_matrix(y_test, preds)\n",
    "    print(mat)\n",
    "    acc=(mat[0][0]+mat[1][1])/(mat[0][0]+mat[1][1]+mat[0][1]+mat[1][0])\n",
    "    print(acc)\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6576    0    0    0    0    3    0    0]\n",
      " [  25    0    0    0    0    0    0    0]\n",
      " [ 104    0    0    0    0    2    0    0]\n",
      " [  42    0    0    0    0   11    0    0]\n",
      " [ 323    0    0    0    0    2    0    0]\n",
      " [ 889    0    0    0    0  299    0    0]\n",
      " [ 800    0    0    0    0    3    0    0]\n",
      " [ 375    0    0    0    0    1    0   41]]\n",
      "0.9962126950462051\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      6579\n",
      "           1       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00        53\n",
      "           4       0.00      0.00      0.00       325\n",
      "           5       0.93      0.25      0.40      1188\n",
      "           6       0.00      0.00      0.00       803\n",
      "           7       1.00      0.10      0.18       417\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      9496\n",
      "   macro avg       0.33      0.17      0.18      9496\n",
      "weighted avg       0.66      0.73      0.64      9496\n",
      "\n",
      "[[6532    0    0    0    0   31   13    3]\n",
      " [  25    0    0    0    0    0    0    0]\n",
      " [  95    0    0    0    0   11    0    0]\n",
      " [  24    0    0    0    0   29    0    0]\n",
      " [ 322    0    0    0    0    3    0    0]\n",
      " [ 838    0    0    0    0  350    0    0]\n",
      " [ 800    0    0    0    0    1    2    0]\n",
      " [ 318    0    0    0    0    5    4   90]]\n",
      "0.9961872807686442\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84      6579\n",
      "           1       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00        53\n",
      "           4       0.00      0.00      0.00       325\n",
      "           5       0.81      0.29      0.43      1188\n",
      "           6       0.11      0.00      0.00       803\n",
      "           7       0.97      0.22      0.35       417\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      9496\n",
      "   macro avg       0.33      0.19      0.20      9496\n",
      "weighted avg       0.66      0.73      0.65      9496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khandalaryan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/khandalaryan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6579    0    0    0    0    0    0    0]\n",
      " [  25    0    0    0    0    0    0    0]\n",
      " [ 106    0    0    0    0    0    0    0]\n",
      " [  53    0    0    0    0    0    0    0]\n",
      " [ 325    0    0    0    0    0    0    0]\n",
      " [1151    0    0    0    0   37    0    0]\n",
      " [ 803    0    0    0    0    0    0    0]\n",
      " [ 417    0    0    0    0    0    0    0]]\n",
      "0.9962144155057541\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82      6579\n",
      "           1       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00        53\n",
      "           4       0.00      0.00      0.00       325\n",
      "           5       1.00      0.03      0.06      1188\n",
      "           6       0.00      0.00      0.00       803\n",
      "           7       0.00      0.00      0.00       417\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      9496\n",
      "   macro avg       0.21      0.13      0.11      9496\n",
      "weighted avg       0.61      0.70      0.58      9496\n",
      "\n",
      "[[6562    0    0    5    1    8    2    1]\n",
      " [  24    1    0    0    0    0    0    0]\n",
      " [  19    0   87    0    0    0    0    0]\n",
      " [  11    0    0   37    0    5    0    0]\n",
      " [ 314    0    0    0    5    6    0    0]\n",
      " [ 797    0    0    3    0  387    0    1]\n",
      " [ 788    0    0    0    1    2    3    9]\n",
      " [ 299    0    0    0    0    1    0  117]]\n",
      "0.9963564596933353\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85      6579\n",
      "           1       1.00      0.04      0.08        25\n",
      "           2       1.00      0.82      0.90       106\n",
      "           3       0.82      0.70      0.76        53\n",
      "           4       0.71      0.02      0.03       325\n",
      "           5       0.95      0.33      0.48      1188\n",
      "           6       0.60      0.00      0.01       803\n",
      "           7       0.91      0.28      0.43       417\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      9496\n",
      "   macro avg       0.84      0.40      0.44      9496\n",
      "weighted avg       0.77      0.76      0.69      9496\n",
      "\n",
      "[[4940    7    3    9   83 1150  297   90]\n",
      " [  12    2    0    0    1    7    3    0]\n",
      " [  13    0   88    1    1    1    2    0]\n",
      " [   2    0    0   38    0   11    2    0]\n",
      " [ 172    1    0    0   20   98   23   11]\n",
      " [ 291    0    0    7   16  807   46   21]\n",
      " [ 363    1    1    0   20  254  127   37]\n",
      " [ 146    0    0    1    1   86   46  137]]\n",
      "0.9961701269905261\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      6579\n",
      "           1       0.18      0.08      0.11        25\n",
      "           2       0.96      0.83      0.89       106\n",
      "           3       0.68      0.72      0.70        53\n",
      "           4       0.14      0.06      0.09       325\n",
      "           5       0.33      0.68      0.45      1188\n",
      "           6       0.23      0.16      0.19       803\n",
      "           7       0.46      0.33      0.38       417\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      9496\n",
      "   macro avg       0.48      0.45      0.45      9496\n",
      "weighted avg       0.68      0.65      0.65      9496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "nb = MultinomialNB()\n",
    "fitpred(nb)\n",
    "nb2 = BernoulliNB()\n",
    "fitpred(nb2)\n",
    "clf = svm.SVC(gamma='scale')\n",
    "fitpred(clf)\n",
    "clf2 = xgb.XGBClassifier()\n",
    "fitpred(clf2)\n",
    "clf3 = DecisionTreeClassifier()\n",
    "fitpred(clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbf = xgb.XGBClassifier()\n",
    "nbf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = test['Title']\n",
    "X_t = bow_transformer.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nbf.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = le.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BOOK', 'BOOK', 'SOUNDDISC', ..., 'BOOK', 'BOOK', 'SOUNDDISC'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31654</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31655</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31656</td>\n",
       "      <td>SOUNDDISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31657</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31658</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31659</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31660</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31661</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31662</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31663</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31664</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31665</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31666</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31667</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31668</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31669</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31670</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31671</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31672</td>\n",
       "      <td>SOUNDDISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31673</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31674</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31675</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31676</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31677</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31678</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID MaterialType\n",
       "0   31654         BOOK\n",
       "1   31655         BOOK\n",
       "2   31656    SOUNDDISC\n",
       "3   31657         BOOK\n",
       "4   31658         BOOK\n",
       "5   31659         BOOK\n",
       "6   31660         BOOK\n",
       "7   31661         BOOK\n",
       "8   31662         BOOK\n",
       "9   31663         BOOK\n",
       "10  31664         BOOK\n",
       "11  31665         BOOK\n",
       "12  31666         BOOK\n",
       "13  31667         BOOK\n",
       "14  31668         BOOK\n",
       "15  31669         BOOK\n",
       "16  31670         BOOK\n",
       "17  31671         BOOK\n",
       "18  31672    SOUNDDISC\n",
       "19  31673         BOOK\n",
       "20  31674         BOOK\n",
       "21  31675         BOOK\n",
       "22  31676         BOOK\n",
       "23  31677         BOOK\n",
       "24  31678         BOOK"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = test['ID']\n",
    "label = preds\n",
    "data = { 'ID': id_, 'MaterialType': label}\n",
    "submission = pd.DataFrame(data)\n",
    "submission.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgb.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
